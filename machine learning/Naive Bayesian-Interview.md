-   朴素贝叶斯与LR的区别？ 

  > 1. 朴素贝叶斯是生成模型，根据已有样本进行贝叶斯估计学习出先验概率P(Y)和条件概率P(X|Y)，进而求出联合分布概率P(XY),最后利用贝叶斯定理求解P(Y|X) ;
  >
  >    LR是判别模型，根据极大化对数似然函数直接求出条件概率P(Y|X) 。不关心样本中类别的比例及类别下出现特征的概率，它直接给出预测模型的式子。设每个特征都有一个权重，训练样本数据更新权重w，得出最终表达式。 
  >
  > 2. 朴素贝叶斯是基于很强的条件独立假设（在已知分类Y的条件下，各个特征变量取值是相互独立的），而LR则对此没有要求。
  >
  > 3. 朴素贝叶斯适用于数据集少的情景，而LR适用于大规模数据集。 

-  朴素贝叶斯“朴素”在哪里？ 

  > 利用贝叶斯定理求解联合概率P(XY)时，需要计算条件概率P(X|Y)。在计算P(X|Y)时，朴素贝叶斯做了一个很强的条件独立假设（当Y确定时，X的各个分量取值之间相互独立）。 

- 什么是 半朴素贝叶斯 ？

  > 全部属性独立很难实现，于是对条件独立假设进行一定程度上的放松。
  >
  > 考虑一部分属性间的相互依赖信息，从而既不需进行完全联合概率计算，又不至于彻底忽略了比较强的属性依赖关系。
  >
  > **独依赖**关系是半朴素贝叶斯分类器最常用的一种策略。

- 在估计条件概率P(X|Y)时出现概率为0的情况怎么办？ 

  >  引入λ，当λ=1时称为拉普拉斯平滑。 

- 朴素贝叶斯的优缺点？

  > 优点
  >
  > - 有稳定的分类效率，速度快
  > - 对缺失数据不太敏感
  > - 适合多分类任务
  > - 适合增量式训练
  > - 对小规模的数据表现很好 
  >
  >  
  >
  > 缺点
  >
  > -  理论上，朴素贝叶斯模型与其他分类方法相比具有最小的误差率。但是实际上并非总是如此，这是因为朴素贝叶斯模型假设属性之间相互独立，这个假设在实际应用中往往是不成立的 
  > -  属性个数比较多或者属性之间相关性较大时，分类效果不好
  > -   需要知道先验概率，且先验概率很多时候取决于假设，假设的模型可以有很多种，因此在某些时候会由于假设的先验模型的原因导致预测效果不佳
  > -  对输入数据的表达形式很敏感（离散、连续，值极大极小之类的）

- 为什么属性独立性假设在实际情况中很难成立，但朴素贝叶斯仍能取得较好的效果？

  > 1. 对于分类任务来说，只要各类别的条件概率排序正确、无需精准概率值即可导致正确分类； 
  > 2. 如果属性间依赖对所有类别影响相同，或依赖关系的影响能相互抵消，则属性条件独立性假设在降低计算开销的同时不会对性能产生负面影响。 

- 后验概率最大化准则意义？ 

  > 朴素贝叶斯法将实例分到后验概率最大化的类中。这等价与期望风险最小化。假设选取的是0-1损失函数， 

- 应用场景？

  > 文本分类（词袋模型）
  >
  > 邮件过滤
  >
  > 情感分析
  >
  > 医疗领域
  >
  > 推荐系统（朴素贝叶斯+协同过滤）
  >
  > 拼写矫正

- NB 应用于文本分类存在哪三种模型？

  > 多项式模型 ： 计算句子概率，统计词语时，重复的词语视为其出现多次 
  >
  > 伯努利（0-1）模型：计算句子概率、统计词语时，将重复出现的词语视为一次 
  >
  > 混合模型：计算句子概率时，不考虑重复词语出现的次数，但在计算词语的概率时考虑其出现的次数 

- 什么是平滑？（**TODO**）

  > 如果某个特征 $x_I$ 没有出现过，在贝叶斯公式中 $p(x_i|y = c_k)=0$，因此借助平滑技术，在增加未出现词语的同事，减少已出现词语的概率，保证所有词语概略相加为1，常见有以下三种方式：
  >
  > 1. 拉普拉斯平滑： 在分子上加1,对于先验概率，在分母上加上训练集中可能的类别数；对于条件概率，则在分母上加上第i个属性可能的取值数 
  > 2. 线性插值
  > 3. 回退

- NB 如何处理连续数值？（**TODO**）

  > 离散化
  >
  > 使用概率密度函数

- NB如何处理缺失值？

  > 直接忽略

- 什么是先验概率、条件概率、后验概率？

  > **先验概率**： 所谓先验概率，就是根据以往的经验或者现有数据的分析所得到的概率。如，随机扔一枚硬币，则p(正面) = p(反面) = 1/2 
  >
  > **条件概率**：所谓条件概率是指事件A在另一事件B发生的条件下发生的概率。用数学符号表示为：P(B|A)，即B在A发生的条件下发生的概率。举个栗子，你早上误喝了一瓶过期了的牛奶（A），那我们来算一下你今天拉肚子的概率（B），这个就叫做条件概率。即P（拉肚子|喝了过期牛奶）， 易见，条件概率是**有因求果**（知道原因推测结果）
  >
  > **后验概率**：后验概率跟条件概率的表达形式有点相似。数学表达式为p(A|B), 即A在B发生的条件下发生的概率。以误喝牛奶的例子为例，现在知道了你今天拉肚子了（B），算一下你早上误喝了一瓶过期了的牛奶(A)的概率, 即P（A|B），这就是后验概率，后验概率是**有果求因**（知道结果推出原因） 

- 朴素贝叶斯的工作流程？

  > 1.  准备阶段 ： 主要工作是根据具体情况确定特征属性，去除高度相关性的属性(如果两个属性具有高度相关性的话，那么该属性将会在模型中发挥了2次作用，会使得朴素贝叶斯所预测的结果向该属性所希望的方向偏离，导致分类出现偏差) 
  > 2. 分类器训练阶段： 计算每个类别在训练样本中的出现频率及每个特征属性划分对每个类别的条件概率估计，并将结果记录 
  > 3.  应用阶段：这个阶段的任务是使用分类器对待分类项进行分类 

- 朴素贝叶斯中有没有超参数可以调？

  > 朴素贝叶斯是没有超参数可以调的，所以它不需要调参，朴素贝叶斯是根据训练集进行分类，分类出来的结果基本上就是确定了的 

- 朴素贝叶斯中有多少种模型？（**TODO**）

  > 1. 高斯模型：对连续型数据进行处理
  > 2. 多项式模型： 对离散型数据进行处理 
  > 3. 伯努利模型 

- 朴素贝叶斯对异常值敏不敏感？

  >  朴素贝叶斯对异常值不敏感。所以在进行数据处理时，我们可以不去除异常值，去除异常值则可能在进行预测的过程中由于失去部分异常值导致模型的泛化能力下降。 

- 朴素贝叶斯是高方差还是低方差模型？

  >  朴素贝叶斯是低方差模型。 (误差 = 偏差 + 方差)对于复杂模型来说，由于复杂模型充分拟合了部分数据，使得它们的偏差变小，但由于对部分数据过分拟合，这就导致预测的方差会变大。因为朴素贝叶斯假设了各个属性之间是相互的，算是一个简单的模型。对于简单的模型来说，则恰恰相反，简单模型的偏差会更大，相对的，方差就会较小。


